{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes NB - Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<p>\n",
    "DonorsChoose.org receives hundreds of thousands of project proposals each year for classroom projects in need of funding. Right now, a large number of volunteers is needed to manually screen each submission before it's approved to be posted on the DonorsChoose.org website.\n",
    "</p>\n",
    "<p>\n",
    "    Next year, DonorsChoose.org expects to receive close to 500,000 project proposals. As a result, there are three main problems they need to solve:\n",
    "<ul>\n",
    "<li>\n",
    "    How to scale current manual processes and resources to screen 500,000 projects so that they can be posted as quickly and as efficiently as possible</li>F\n",
    "    <li>How to increase the consistency of project vetting across different volunteers to improve the experience for teachers</li>\n",
    "    <li>How to focus volunteer time on the applications that need the most assistance</li>\n",
    "    </ul>\n",
    "</p>    \n",
    "<p>\n",
    "The goal of the competition is to predict whether or not a DonorsChoose.org project proposal submitted by a teacher will be approved, using the text of project descriptions as well as additional metadata about the project, teacher, and school. DonorsChoose.org can then use this information to identify projects most likely to need further review before approval.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes on the Essay Data\n",
    "\n",
    "<ul>\n",
    "Prior to May 17, 2016, the prompts for the essays were as follows:\n",
    "<li>__project_essay_1:__ \"Introduce us to your classroom\"</li>\n",
    "<li>__project_essay_2:__ \"Tell us more about your students\"</li>\n",
    "<li>__project_essay_3:__ \"Describe how your students will use the materials you're requesting\"</li>\n",
    "<li>__project_essay_3:__ \"Close by sharing why your project will make a difference\"</li>\n",
    "</ul>\n",
    "\n",
    "\n",
    "<ul>\n",
    "Starting on May 17, 2016, the number of essays was reduced from 4 to 2, and the prompts for the first 2 essays were changed to the following:<br>\n",
    "<li>__project_essay_1:__ \"Describe your students: What makes your students special? Specific details about their background, your neighborhood, and your school are all helpful.\"</li>\n",
    "<li>__project_essay_2:__ \"About your project: How will these materials make a difference in your students' learning and improve their school lives?\"</li>\n",
    "<br>For all projects with project_submitted_datetime of 2016-05-17 and later, the values of project_essay_3 and project_essay_4 will be NaN.\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import the necessary Libraries\n",
    "we will need to import libraries that allow for data analysis and data visualization to get acclimated to the dataset. We will be using pandas, numpy, matplotlib and seaborn to conduct this. Data Exploration libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning, module='gensim')\n",
    "warnings.filterwarnings(\"ignore\",'detected Windows; aliasing chunkize to chunkize_serial')\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\n",
    "\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "import re\n",
    "# Tutorial about Python regular expressions: https://pymotw.com/2/re/\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Read in the dataset.\n",
    "We will use the pandas .read_csv() method to read in the dataset. Then we will use the. head() method to observe the first few rows of the data, to understand the information better. In our case, the feature(column) headers tell us pretty little. This is fine because we are merely trying to gain insight via classifying new data points by referencing it’s neighboring elements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_data = pd.read_csv(\"C:\\\\VipinML\\\\Assignment 2\\\\Assignments_DonorsChoose_2018\\\\train_data.csv\")\n",
    "resource_data = pd.read_csv(\"C:\\\\VipinML\\Assignment 2\\\\Assignments_DonorsChoose_2018\\\\resources.csv\")\n",
    "#Limit the data for testing purpose since processing takes few hours for full set..\n",
    "\n",
    "project_data = project_data.head(100000)\n",
    "resource_data = resource_data.head(100000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data points in train data (100000, 17)\n",
      "--------------------------------------------------\n",
      "The attributes of data : ['Unnamed: 0' 'id' 'teacher_id' 'teacher_prefix' 'school_state'\n",
      " 'project_submitted_datetime' 'project_grade_category'\n",
      " 'project_subject_categories' 'project_subject_subcategories'\n",
      " 'project_title' 'project_essay_1' 'project_essay_2' 'project_essay_3'\n",
      " 'project_essay_4' 'project_resource_summary'\n",
      " 'teacher_number_of_previously_posted_projects' 'project_is_approved']\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of data points in train data\", project_data.shape)\n",
    "print('-'*50)\n",
    "print(\"The attributes of data :\", project_data.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>teacher_id</th>\n",
       "      <th>teacher_prefix</th>\n",
       "      <th>school_state</th>\n",
       "      <th>Date</th>\n",
       "      <th>project_grade_category</th>\n",
       "      <th>project_subject_categories</th>\n",
       "      <th>project_subject_subcategories</th>\n",
       "      <th>project_title</th>\n",
       "      <th>project_essay_1</th>\n",
       "      <th>project_essay_2</th>\n",
       "      <th>project_essay_3</th>\n",
       "      <th>project_essay_4</th>\n",
       "      <th>project_resource_summary</th>\n",
       "      <th>teacher_number_of_previously_posted_projects</th>\n",
       "      <th>project_is_approved</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55660</th>\n",
       "      <td>8393</td>\n",
       "      <td>p205479</td>\n",
       "      <td>2bf07ba08945e5d8b2a3f269b2b3cfe5</td>\n",
       "      <td>Mrs.</td>\n",
       "      <td>CA</td>\n",
       "      <td>2016-04-27 00:27:36</td>\n",
       "      <td>Grades PreK-2</td>\n",
       "      <td>Math &amp; Science</td>\n",
       "      <td>Applied Sciences, Health &amp; Life Science</td>\n",
       "      <td>Engineering STEAM into the Primary Classroom</td>\n",
       "      <td>I have been fortunate enough to use the Fairy ...</td>\n",
       "      <td>My students come from a variety of backgrounds...</td>\n",
       "      <td>Each month I try to do several science or STEM...</td>\n",
       "      <td>It is challenging to develop high quality scie...</td>\n",
       "      <td>My students need STEM kits to learn critical s...</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0       id                        teacher_id teacher_prefix  \\\n",
       "55660        8393  p205479  2bf07ba08945e5d8b2a3f269b2b3cfe5           Mrs.   \n",
       "\n",
       "      school_state                Date project_grade_category  \\\n",
       "55660           CA 2016-04-27 00:27:36          Grades PreK-2   \n",
       "\n",
       "      project_subject_categories            project_subject_subcategories  \\\n",
       "55660             Math & Science  Applied Sciences, Health & Life Science   \n",
       "\n",
       "                                      project_title  \\\n",
       "55660  Engineering STEAM into the Primary Classroom   \n",
       "\n",
       "                                         project_essay_1  \\\n",
       "55660  I have been fortunate enough to use the Fairy ...   \n",
       "\n",
       "                                         project_essay_2  \\\n",
       "55660  My students come from a variety of backgrounds...   \n",
       "\n",
       "                                         project_essay_3  \\\n",
       "55660  Each month I try to do several science or STEM...   \n",
       "\n",
       "                                         project_essay_4  \\\n",
       "55660  It is challenging to develop high quality scie...   \n",
       "\n",
       "                                project_resource_summary  \\\n",
       "55660  My students need STEM kits to learn critical s...   \n",
       "\n",
       "       teacher_number_of_previously_posted_projects  project_is_approved  \n",
       "55660                                            53                    1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how to replace elements in list python: https://stackoverflow.com/a/2582163/4084039\n",
    "cols = ['Date' if x=='project_submitted_datetime' else x for x in list(project_data.columns)]\n",
    "#sort dataframe based on time pandas python: https://stackoverflow.com/a/49702492/4084039\n",
    "project_data['Date'] = pd.to_datetime(project_data['project_submitted_datetime'])\n",
    "project_data.drop('project_submitted_datetime', axis=1, inplace=True)\n",
    "project_data.sort_values(by=['Date'], inplace=True)\n",
    "\n",
    "# how to reorder columns pandas python: https://stackoverflow.com/a/13148611/4084039\n",
    "project_data = project_data[cols]\n",
    "project_data.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect All Features into global List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of features to appned all the features for BoW, TFIDF and std catagories.\n",
    "features_bow =[]\n",
    "features_tfidf= []\n",
    "features_std =[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 preprocessing of `project_subject_categories`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/a/47091490/4084039\n",
    "import re\n",
    "def decontracted(phrase):\n",
    "    # specific\n",
    "    phrase = re.sub(r\"won't\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "\n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocesssing_cleanup(text):\n",
    "    # Combining all the above stundents \n",
    "   \n",
    "    from tqdm import tqdm\n",
    "    X_text = []\n",
    "    # tqdm is for printing the status bar\n",
    "    for sentance in tqdm(text):\n",
    "        print (sentance)\n",
    "        sent = decontracted(sentance)\n",
    "        sent = sent.replace('\\\\r', ' ')\n",
    "        sent = sent.replace('\\\\\"', ' ')\n",
    "        sent = sent.replace('\\\\n', ' ')\n",
    "        sent = re.sub('[^A-Za-z0-9]+', ' ', sent)\n",
    "        # https://gist.github.com/sebleier/554280\n",
    "        sent = ' '.join(e for e in sent.split() if e not in stopwords)\n",
    "        X_text.append(sent.lower().strip())\n",
    "       # print (X_train_preprocessed_essays)\n",
    "    return X_text\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "catogories = list(project_data['project_subject_categories'].values)\n",
    "# remove special characters from list of strings python: https://stackoverflow.com/a/47301924/4084039\n",
    "\n",
    "# https://www.geeksforgeeks.org/removing-stop-words-nltk-python/\n",
    "# https://stackoverflow.com/questions/23669024/how-to-strip-a-specific-word-from-a-string\n",
    "# https://stackoverflow.com/questions/8270092/remove-all-whitespace-in-a-string-in-python\n",
    "cat_list = []\n",
    "for i in catogories:\n",
    "    temp = \"\"\n",
    "    # consider we have text like this \"Math & Science, Warmth, Care & Hunger\"\n",
    "    for j in i.split(','): # it will split it in three parts [\"Math & Science\", \"Warmth\", \"Care & Hunger\"]\n",
    "        if 'The' in j.split(): # this will split each of the catogory based on space \"Math & Science\"=> \"Math\",\"&\", \"Science\"\n",
    "            j=j.replace('The','') # if we have the words \"The\" we are going to replace it with ''(i.e removing 'The')\n",
    "        j = j.replace(' ','') # we are placeing all the ' '(space) with ''(empty) ex:\"Math & Science\"=>\"Math&Science\"\n",
    "        temp+=j.strip()+\" \" #\" abc \".strip() will return \"abc\", remove the trailing spaces\n",
    "        temp = temp.replace('&','_') # we are replacing the & value into \n",
    "    cat_list.append(temp.strip())\n",
    "    \n",
    "project_data['clean_categories'] = cat_list\n",
    "project_data.drop(['project_subject_categories'], axis=1, inplace=True)\n",
    "\n",
    "from collections import Counter\n",
    "my_counter = Counter()\n",
    "for word in project_data['clean_categories'].values:\n",
    "    my_counter.update(word.split())\n",
    "\n",
    "cat_dict = dict(my_counter)\n",
    "sorted_cat_dict = dict(sorted(cat_dict.items(), key=lambda kv: kv[1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 preprocessing of `project_subject_subcategories`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_catogories = list(project_data['project_subject_subcategories'].values)\n",
    "# remove special characters from list of strings python: https://stackoverflow.com/a/47301924/4084039\n",
    "\n",
    "# https://www.geeksforgeeks.org/removing-stop-words-nltk-python/\n",
    "# https://stackoverflow.com/questions/23669024/how-to-strip-a-specific-word-from-a-string\n",
    "# https://stackoverflow.com/questions/8270092/remove-all-whitespace-in-a-string-in-python\n",
    "\n",
    "sub_cat_list = []\n",
    "for i in sub_catogories:\n",
    "    temp = \"\"\n",
    "    # consider we have text like this \"Math & Science, Warmth, Care & Hunger\"\n",
    "    for j in i.split(','): # it will split it in three parts [\"Math & Science\", \"Warmth\", \"Care & Hunger\"]\n",
    "        if 'The' in j.split(): # this will split each of the catogory based on space \"Math & Science\"=> \"Math\",\"&\", \"Science\"\n",
    "            j=j.replace('The','') # if we have the words \"The\" we are going to replace it with ''(i.e removing 'The')\n",
    "        j = j.replace(' ','') # we are placeing all the ' '(space) with ''(empty) ex:\"Math & Science\"=>\"Math&Science\"\n",
    "        temp +=j.strip()+\" \"#\" abc \".strip() will return \"abc\", remove the trailing spaces\n",
    "        temp = temp.replace('&','_')\n",
    "    sub_cat_list.append(temp.strip())\n",
    "\n",
    "project_data['clean_subcategories'] = sub_cat_list\n",
    "project_data.drop(['project_subject_subcategories'], axis=1, inplace=True)\n",
    "\n",
    "# count of all the words in corpus python: https://stackoverflow.com/a/22898595/4084039\n",
    "my_counter = Counter()\n",
    "for word in project_data['clean_subcategories'].values:\n",
    "    my_counter.update(word.split())\n",
    "    \n",
    "sub_cat_dict = dict(my_counter)\n",
    "sorted_sub_cat_dict = dict(sorted(sub_cat_dict.items(), key=lambda kv: kv[1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_cat = list(project_data['teacher_prefix'].values)\n",
    "# remove special characters from list of strings python: https://stackoverflow.com/a/47301924/4084039\n",
    "\n",
    "# https://www.geeksforgeeks.org/removing-stop-words-nltk-python/\n",
    "# https://stackoverflow.com/questions/23669024/how-to-strip-a-specific-word-from-a-string\n",
    "# https://stackoverflow.com/questions/8270092/remove-all-whitespace-in-a-string-in-python\n",
    "cat_list = []\n",
    "for i in teacher_cat:\n",
    "    temp = \"\"\n",
    "    # consider we have text like this \"Math & Science, Warmth, Care & Hunger\"\n",
    "    j = j.replace(' ','') # we are placeing all the ' '(space) with ''(empty) ex:\"Math & Science\"=>\"Math&Science\"\n",
    "    temp+=j.strip()+\" \" #\" abc \".strip() will return \"abc\", remove the trailing spaces\n",
    "    temp = temp.replace('&','_') # we are replacing the & value into \n",
    "    cat_list.append(temp.strip())\n",
    "\n",
    "\n",
    "project_data.drop(['teacher_prefix'], axis=1, inplace=True)\n",
    "project_data['teacher_prefix'] = sub_cat_list\n",
    "    \n",
    "from collections import Counter\n",
    "my_counter = Counter()\n",
    "for word in project_data['teacher_prefix'].values:\n",
    "    my_counter.update(word.split())\n",
    "\n",
    "cat_dict = dict(my_counter)\n",
    "sorted_teacher_dict = dict(sorted(cat_dict.items(), key=lambda kv: kv[1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge two column text dataframe: \n",
    "project_data[\"essay\"] = project_data[\"project_essay_1\"].map(str) +\\\n",
    "                        project_data[\"project_essay_2\"].map(str) + \\\n",
    "                        project_data[\"project_essay_3\"].map(str) + \\\n",
    "                        project_data[\"project_essay_4\"].map(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>teacher_id</th>\n",
       "      <th>school_state</th>\n",
       "      <th>Date</th>\n",
       "      <th>project_grade_category</th>\n",
       "      <th>project_title</th>\n",
       "      <th>project_essay_1</th>\n",
       "      <th>project_essay_2</th>\n",
       "      <th>project_essay_3</th>\n",
       "      <th>project_essay_4</th>\n",
       "      <th>project_resource_summary</th>\n",
       "      <th>teacher_number_of_previously_posted_projects</th>\n",
       "      <th>project_is_approved</th>\n",
       "      <th>clean_categories</th>\n",
       "      <th>clean_subcategories</th>\n",
       "      <th>teacher_prefix</th>\n",
       "      <th>essay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55660</th>\n",
       "      <td>8393</td>\n",
       "      <td>p205479</td>\n",
       "      <td>2bf07ba08945e5d8b2a3f269b2b3cfe5</td>\n",
       "      <td>CA</td>\n",
       "      <td>2016-04-27 00:27:36</td>\n",
       "      <td>Grades PreK-2</td>\n",
       "      <td>Engineering STEAM into the Primary Classroom</td>\n",
       "      <td>I have been fortunate enough to use the Fairy ...</td>\n",
       "      <td>My students come from a variety of backgrounds...</td>\n",
       "      <td>Each month I try to do several science or STEM...</td>\n",
       "      <td>It is challenging to develop high quality scie...</td>\n",
       "      <td>My students need STEM kits to learn critical s...</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>Math_Science</td>\n",
       "      <td>AppliedSciences Health_LifeScience</td>\n",
       "      <td>AppliedSciences Health_LifeScience</td>\n",
       "      <td>I have been fortunate enough to use the Fairy ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0       id                        teacher_id school_state  \\\n",
       "55660        8393  p205479  2bf07ba08945e5d8b2a3f269b2b3cfe5           CA   \n",
       "\n",
       "                     Date project_grade_category  \\\n",
       "55660 2016-04-27 00:27:36          Grades PreK-2   \n",
       "\n",
       "                                      project_title  \\\n",
       "55660  Engineering STEAM into the Primary Classroom   \n",
       "\n",
       "                                         project_essay_1  \\\n",
       "55660  I have been fortunate enough to use the Fairy ...   \n",
       "\n",
       "                                         project_essay_2  \\\n",
       "55660  My students come from a variety of backgrounds...   \n",
       "\n",
       "                                         project_essay_3  \\\n",
       "55660  Each month I try to do several science or STEM...   \n",
       "\n",
       "                                         project_essay_4  \\\n",
       "55660  It is challenging to develop high quality scie...   \n",
       "\n",
       "                                project_resource_summary  \\\n",
       "55660  My students need STEM kits to learn critical s...   \n",
       "\n",
       "       teacher_number_of_previously_posted_projects  project_is_approved  \\\n",
       "55660                                            53                    1   \n",
       "\n",
       "      clean_categories                 clean_subcategories  \\\n",
       "55660     Math_Science  AppliedSciences Health_LifeScience   \n",
       "\n",
       "                           teacher_prefix  \\\n",
       "55660  AppliedSciences Health_LifeScience   \n",
       "\n",
       "                                                   essay  \n",
       "55660  I have been fortunate enough to use the Fairy ...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 1.4.2.3 Using Pretrained Models: TFIDF weighted W2V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/a/47091490/4084039\n",
    "import re\n",
    "\n",
    "def decontracted(phrase):\n",
    "    # specific\n",
    "    phrase = re.sub(r\"won't\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "\n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LTexas PE is different than most schools. Our kids get PE everyday and they love it!From 7:45am-3:00pm 1,400 kids ranging from Kinder-8th grade come through our gym EVERYDAY! As coaches we are always\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "sent = decontracted(project_data['essay'].values[500])\n",
    "print(sent[1:200])\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LTexas PE is different than most schools. Our kids get PE everyday and they love it!From 7:45am-3:00pm 1,400 kids ranging from Kinder-8th grade come through our gym EVERYDAY! As coaches we are always\n",
      "LTexas PE is different than most schools. Our kids get PE everyday and they love it!From 7:45am-3:00pm 1,400 kids ranging from Kinder-8th grade come through our gym EVERYDAY! As coaches we are always\n"
     ]
    }
   ],
   "source": [
    "# \\r \\n \\t remove from string python: http://texthandler.com/info/remove-line-breaks-python/\n",
    "sent = sent.replace('\\\\r', ' ')\n",
    "sent = sent.replace('\\\\\"', ' ')\n",
    "sent = sent.replace('\\\\n', ' ')\n",
    "print(sent[1:200])\n",
    "print(sent[1:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LTexas PE is different than most schools Our kids get PE everyday and they love it From 7 45am 3 00pm 1 400 kids ranging from Kinder 8th grade come through our gym EVERYDAY As coaches we are always h\n"
     ]
    }
   ],
   "source": [
    "#remove spacial character: https://stackoverflow.com/a/5843547/4084039\n",
    "sent = re.sub('[^A-Za-z0-9]+', ' ', sent)\n",
    "print(sent[1:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://gist.github.com/sebleier/554280\n",
    "# we are removing the words from the stop words list: 'no', 'nor', 'not'\n",
    "stopwords= ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\",\\\n",
    "            \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', \\\n",
    "            'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their',\\\n",
    "            'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', \\\n",
    "            'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', \\\n",
    "            'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', \\\n",
    "            'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after',\\\n",
    "            'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further',\\\n",
    "            'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\\\n",
    "            'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', \\\n",
    "            's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', \\\n",
    "            've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn',\\\n",
    "            \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn',\\\n",
    "            \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", \\\n",
    "            'won', \"won't\", 'wouldn', \"wouldn't\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.3 Merging price with project_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id   price  quantity\n",
      "1  p000031  357.98         2\n",
      "2  p000052  114.98         2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>teacher_id</th>\n",
       "      <th>school_state</th>\n",
       "      <th>Date</th>\n",
       "      <th>project_grade_category</th>\n",
       "      <th>project_title</th>\n",
       "      <th>project_essay_1</th>\n",
       "      <th>project_essay_2</th>\n",
       "      <th>project_essay_3</th>\n",
       "      <th>project_essay_4</th>\n",
       "      <th>project_resource_summary</th>\n",
       "      <th>teacher_number_of_previously_posted_projects</th>\n",
       "      <th>project_is_approved</th>\n",
       "      <th>clean_categories</th>\n",
       "      <th>clean_subcategories</th>\n",
       "      <th>teacher_prefix</th>\n",
       "      <th>essay</th>\n",
       "      <th>price</th>\n",
       "      <th>quantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8393</td>\n",
       "      <td>p205479</td>\n",
       "      <td>2bf07ba08945e5d8b2a3f269b2b3cfe5</td>\n",
       "      <td>CA</td>\n",
       "      <td>2016-04-27 00:27:36</td>\n",
       "      <td>Grades PreK-2</td>\n",
       "      <td>Engineering STEAM into the Primary Classroom</td>\n",
       "      <td>I have been fortunate enough to use the Fairy ...</td>\n",
       "      <td>My students come from a variety of backgrounds...</td>\n",
       "      <td>Each month I try to do several science or STEM...</td>\n",
       "      <td>It is challenging to develop high quality scie...</td>\n",
       "      <td>My students need STEM kits to learn critical s...</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>Math_Science</td>\n",
       "      <td>AppliedSciences Health_LifeScience</td>\n",
       "      <td>AppliedSciences Health_LifeScience</td>\n",
       "      <td>I have been fortunate enough to use the Fairy ...</td>\n",
       "      <td>725.05</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0       id                        teacher_id school_state  \\\n",
       "0        8393  p205479  2bf07ba08945e5d8b2a3f269b2b3cfe5           CA   \n",
       "\n",
       "                 Date project_grade_category  \\\n",
       "0 2016-04-27 00:27:36          Grades PreK-2   \n",
       "\n",
       "                                  project_title  \\\n",
       "0  Engineering STEAM into the Primary Classroom   \n",
       "\n",
       "                                     project_essay_1  \\\n",
       "0  I have been fortunate enough to use the Fairy ...   \n",
       "\n",
       "                                     project_essay_2  \\\n",
       "0  My students come from a variety of backgrounds...   \n",
       "\n",
       "                                     project_essay_3  \\\n",
       "0  Each month I try to do several science or STEM...   \n",
       "\n",
       "                                     project_essay_4  \\\n",
       "0  It is challenging to develop high quality scie...   \n",
       "\n",
       "                            project_resource_summary  \\\n",
       "0  My students need STEM kits to learn critical s...   \n",
       "\n",
       "   teacher_number_of_previously_posted_projects  project_is_approved  \\\n",
       "0                                            53                    1   \n",
       "\n",
       "  clean_categories                 clean_subcategories  \\\n",
       "0     Math_Science  AppliedSciences Health_LifeScience   \n",
       "\n",
       "                       teacher_prefix  \\\n",
       "0  AppliedSciences Health_LifeScience   \n",
       "\n",
       "                                               essay   price  quantity  \n",
       "0  I have been fortunate enough to use the Fairy ...  725.05       4.0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_data = resource_data.groupby('id').agg({'price':'sum', 'quantity':'sum'}).reset_index()\n",
    "project_data = pd.merge(project_data, price_data, on='id', how='left')\n",
    "print (price_data[1:3])\n",
    "project_data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert NaN value to mean of the column\n",
    "project_data.fillna(project_data.mean(), inplace=True)\n",
    "project_data.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting data into Train and cross validation(or test): Stratified Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = project_data['project_is_approved'].values\n",
    "X = project_data.drop(['project_is_approved'], axis=1)\n",
    "\n",
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, stratify=y)\n",
    "X_train, X_cv, y_train, y_cv = train_test_split(X_train, y_train, test_size=0.33, stratify=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catogories_essay = list(project_data['essay'].values)\n",
    "# remove special characters from list of strings python: https://stackoverflow.com/a/47301924/4084039\n",
    "\n",
    "# https://www.geeksforgeeks.org/removing-stop-words-nltk-python/\n",
    "# https://stackoverflow.com/questions/23669024/how-to-strip-a-specific-word-from-a-string\n",
    "# https://stackoverflow.com/questions/8270092/remove-all-whitespace-in-a-string-in-python\n",
    "cat_essay_list = []\n",
    "for i in catogories_essay:\n",
    "    temp = \"\"\n",
    "    # consider we have text like this \"Math & Science, Warmth, Care & Hunger\"\n",
    "    for j in i.split(','): # it will split it in three parts [\"Math & Science\", \"Warmth\", \"Care & Hunger\"]\n",
    "        if 'The' in j.split(): # this will split each of the catogory based on space \"Math & Science\"=> \"Math\",\"&\", \"Science\"\n",
    "            j=j.replace('The','') # if we have the words \"The\" we are going to replace it with ''(i.e removing 'The')\n",
    "        j = j.replace(' ','') # we are placeing all the ' '(space) with ''(empty) ex:\"Math & Science\"=>\"Math&Science\"\n",
    "        temp+=j.strip()+\" \" #\" abc \".strip() will return \"abc\", remove the trailing spaces\n",
    "        temp = temp.replace('&','_') # we are replacing the & value into \n",
    "    cat_essay_list.append(temp.strip())\n",
    "    \n",
    "project_data['clean_essay'] = cat_essay_list\n",
    "\n",
    "from collections import Counter\n",
    "my_counter = Counter()\n",
    "for word in project_data['clean_essay'].values:\n",
    "    my_counter.update(word.split())\n",
    "\n",
    "cat_essay_dict = dict(my_counter)\n",
    "sorted_cat_essay_dict = dict(sorted(cat_essay_dict.items(), key=lambda kv: kv[1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catogories_title = list(project_data['project_title'].values)\n",
    "# remove special characters from list of strings python: https://stackoverflow.com/a/47301924/4084039\n",
    "# https://www.geeksforgeeks.org/removing-stop-words-nltk-python/\n",
    "# https://stackoverflow.com/questions/23669024/how-to-strip-a-specific-word-from-a-string\n",
    "# https://stackoverflow.com/questions/8270092/remove-all-whitespace-in-a-string-in-python\n",
    "project_title_list = []\n",
    "for i in catogories_title:\n",
    "    temp = \"\"\n",
    "    # consider we have text like this \"Math & Science, Warmth, Care & Hunger\"\n",
    "    for j in i.split(','): # it will split it in three parts [\"Math & Science\", \"Warmth\", \"Care & Hunger\"]\n",
    "        if 'The' in j.split(): # this will split each of the catogory based on space \"Math & Science\"=> \"Math\",\"&\", \"Science\"\n",
    "            j=j.replace('The','') # if we have the words \"The\" we are going to replace it with ''(i.e removing 'The')\n",
    "        j = j.replace(' ','') # we are placeing all the ' '(space) with ''(empty) ex:\"Math & Science\"=>\"Math&Science\"\n",
    "        temp+=j.strip()+\" \" #\" abc \".strip() will return \"abc\", remove the trailing spaces\n",
    "        temp = temp.replace('&','_') # we are replacing the & value into \n",
    "    project_title_list.append(temp.strip())\n",
    "\n",
    "#project_data.drop('project_title', axis=1, inplace=True)\n",
    "#project_data['project_title'] = project_title_list\n",
    "\n",
    "from collections import Counter\n",
    "my_counter = Counter()\n",
    "for word in project_data['project_title'].values:\n",
    "    my_counter.update(word.split())\n",
    "\n",
    "project_title_dict = dict(my_counter)\n",
    "sorted_project_title_dict = dict(sorted(project_title_dict.items(), key=lambda kv: kv[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining all the above stundents \n",
    "from tqdm import tqdm\n",
    "X_train_preprocessed_essays = []\n",
    "# tqdm is for printing the status bar\n",
    "for sentance in tqdm(X_train['essay'].values):\n",
    "    sent = decontracted(sentance)\n",
    "    sent = sent.replace('\\\\r', ' ')\n",
    "    sent = sent.replace('\\\\\"', ' ')\n",
    "    sent = sent.replace('\\\\n', ' ')\n",
    "    sent = re.sub('[^A-Za-z0-9]+', ' ', sent)\n",
    "    # https://gist.github.com/sebleier/554280\n",
    "    sent = ' '.join(e for e in sent.split() if e not in stopwords)\n",
    "    X_train_preprocessed_essays.append(sent.lower().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining all the above stundents \n",
    "from tqdm import tqdm\n",
    "X_test_preprocessed_essays = []\n",
    "# tqdm is for printing the status bar\n",
    "for sentance in tqdm(X_test['essay'].values):\n",
    "    sent = decontracted(sentance)\n",
    "    sent = sent.replace('\\\\r', ' ')\n",
    "    sent = sent.replace('\\\\\"', ' ')\n",
    "    sent = sent.replace('\\\\n', ' ')\n",
    "    sent = re.sub('[^A-Za-z0-9]+', ' ', sent)\n",
    "    # https://gist.github.com/sebleier/554280\n",
    "    sent = ' '.join(e for e in sent.split() if e not in stopwords)\n",
    "    X_test_preprocessed_essays.append(sent.lower().strip())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining all the above stundents \n",
    "from tqdm import tqdm\n",
    "X_cv_preprocessed_essays = []\n",
    "# tqdm is for printing the status bar\n",
    "for sentance in tqdm(X_cv['essay'].values):\n",
    "    sent = decontracted(sentance)\n",
    "    sent = sent.replace('\\\\r', ' ')\n",
    "    sent = sent.replace('\\\\\"', ' ')\n",
    "    sent = sent.replace('\\\\n', ' ')\n",
    "    sent = re.sub('[^A-Za-z0-9]+', ' ', sent)\n",
    "    # https://gist.github.com/sebleier/554280\n",
    "    sent = ' '.join(e for e in sent.split() if e not in stopwords)\n",
    "    X_cv_preprocessed_essays.append(sent.lower().strip())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Standardize (normalize) the data scale to prep for Naive Bayes algorithm.\n",
    "Because the distance between pairs of points plays a critical part on the classification, it is necessary to normalize the data This will generate an array of values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.1 Vectorizing Categorical data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://www.appliedaicourse.com/course/applied-ai-course-online/lessons/handling-categorical-and-numerical-features/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorization of clean_categories for X_train,X_test, X_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use count vectorizer to convert the values into one \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer_clean_cat = CountVectorizer(min_df=10,ngram_range=(1,4), max_features=100, vocabulary=list(sorted_cat_dict.keys()), lowercase=False, binary=True)\n",
    "X_train_categories_one_hot = vectorizer_clean_cat.transform(X_train['clean_categories'].values)\n",
    "X_test_categories_one_hot = vectorizer_clean_cat.transform(X_test['clean_categories'].values)\n",
    "X_cv_categories_one_hot = vectorizer_clean_cat.transform(X_cv['clean_categories'].values)\n",
    "print(vectorizer_clean_cat.get_feature_names())\n",
    "print(\"Shape of matrix X_train_categories_one_hot  after one hot encodig \",X_train_categories_one_hot.shape)\n",
    "print(\"Shape of matrix X_test_categories_one_hot after one hot encodig \",X_test_categories_one_hot.shape)\n",
    "print(\"Shape of matrix X_cv_categories_one_hot after one hot encodig \",X_cv_categories_one_hot.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorization of clean_subcategories for X_train,X_test, X_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use count vectorizer to convert the values into one \n",
    "vectorizer_sub_cat = CountVectorizer(min_df=10,ngram_range=(1,4), max_features=100,vocabulary=list(sorted_sub_cat_dict.keys()), lowercase=False, binary=True)\n",
    "X_train_sub_categories_one_hot = vectorizer_sub_cat.transform(X_train['clean_subcategories'].values)\n",
    "X_test_sub_categories_one_hot = vectorizer_sub_cat.transform(X_test['clean_subcategories'].values)\n",
    "X_cv_sub_categories_one_hot = vectorizer_sub_cat.transform(X_cv['clean_subcategories'].values)\n",
    "\n",
    "\n",
    "features_tfidf.extend(vectorizer_sub_cat.get_feature_names())\n",
    "features_std.extend(vectorizer_sub_cat.get_feature_names())\n",
    "features_bow.extend(vectorizer_sub_cat.get_feature_names())\n",
    "\n",
    "print(vectorizer_sub_cat.get_feature_names())\n",
    "print(\"Shape of matrix X_train_sub_categories_one_hot  after one hot encodig \",X_train_sub_categories_one_hot.shape)\n",
    "print(\"Shape of matrix X_test_sub_categories_one_hot after oneX_test_sub_categories_one_hot  hot encodig \",X_test_sub_categories_one_hot.shape)\n",
    "print(\"Shape of matrixX_cv_sub_categories_one_hot after one hot encodig \",X_cv_sub_categories_one_hot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can do the similar thing with state, teacher_prefix and project_grade_category also"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.2 Vectorizing Text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stronging variables into pickle files python: http://www.jessicayung.com/how-to-use-pickle-to-save-and-load-variables-in-python/\n",
    "# make sure you have the glove_vectors file\n",
    "with open('C:\\\\VipinML\\\\InputData\\\\glove_vectors', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "    glove_words =  set(model.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorization of preprocessed_essays for X_train,X_test, X_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# average Word2Vec\n",
    "# compute average word2vec for each review.\n",
    "X_train_avg_w2v_vectors = []; # the avg-w2v for each sentence/review is stored in this list\n",
    "for sentence in tqdm(X_train_preprocessed_essays): # for each review/sentence\n",
    "    vector = np.zeros(300) # as word vectors are of zero length\n",
    "    cnt_words =0; # num of words with a valid vector in the sentence/review\n",
    "    for word in sentence.split(): # for each word in a review/sentence\n",
    "        if word in glove_words:\n",
    "            vector += model[word]\n",
    "            cnt_words += 1\n",
    "    if cnt_words != 0:\n",
    "        vector /= cnt_words\n",
    "    X_train_avg_w2v_vectors.append(vector)\n",
    "\n",
    "print(len(X_train_avg_w2v_vectors))\n",
    "print(len(X_train_avg_w2v_vectors[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average Word2Vec\n",
    "# compute average word2vec for each review.\n",
    "X_test_avg_w2v_vectors = []; # the avg-w2v for each sentence/review is stored in this list\n",
    "for sentence in tqdm(X_test_preprocessed_essays): # for each review/sentence\n",
    "    vector = np.zeros(300) # as word vectors are of zero length\n",
    "    cnt_words =0; # num of words with a valid vector in the sentence/review\n",
    "    for word in sentence.split(): # for each word in a review/sentence\n",
    "        if word in glove_words:\n",
    "            vector += model[word]\n",
    "            cnt_words += 1\n",
    "    if cnt_words != 0:\n",
    "        vector /= cnt_words\n",
    "    X_test_avg_w2v_vectors.append(vector)\n",
    "\n",
    "print(len(X_test_avg_w2v_vectors))\n",
    "print(len(X_test_avg_w2v_vectors[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average Word2Vec\n",
    "# compute average word2vec for each review.\n",
    "X_cv_avg_w2v_vectors = []; # the avg-w2v for each sentence/review is stored in this list\n",
    "for sentence in tqdm(X_cv_preprocessed_essays): # for each review/sentence\n",
    "    vector = np.zeros(300) # as word vectors are of zero length\n",
    "    cnt_words =0; # num of words with a valid vector in the sentence/review\n",
    "    for word in sentence.split(): # for each word in a review/sentence\n",
    "        if word in glove_words:\n",
    "            vector += model[word]\n",
    "            cnt_words += 1\n",
    "    if cnt_words != 0:\n",
    "        vector /= cnt_words\n",
    "    X_cv_avg_w2v_vectors.append(vector)\n",
    "\n",
    "print(len(X_cv_avg_w2v_vectors))\n",
    "print(len(X_cv_avg_w2v_vectors[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorization of teacher_prefix  for X_train,X_test, X_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use count vectorizer to convert the values into one hot encoded features\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer_teacher_prefix = CountVectorizer(min_df=10,ngram_range=(1,4), vocabulary=list(sorted_teacher_dict.keys()),max_features=100, lowercase=False, binary=True)\n",
    "X_train_teacher_prefix_data = X_train['teacher_prefix']\n",
    "\n",
    "X_train_teacher_prefix_data.fillna(\"Mrs.\", inplace = True) \n",
    "\n",
    "teacher_prefix_notnull = X_train_teacher_prefix_data[pd.notnull(X_train_teacher_prefix_data)]\n",
    "\n",
    "vectorizer_teacher_prefix.fit(teacher_prefix_notnull.values)\n",
    "\n",
    "X_train_teacher_prefix_one_hot = vectorizer_teacher_prefix.transform(teacher_prefix_notnull.values)\n",
    "print(\"Shape of matrix after one hot encodig \",X_train_teacher_prefix_one_hot.shape)\n",
    "\n",
    "features_bow.extend(vectorizer_teacher_prefix.get_feature_names())\n",
    "features_tfidf.extend(vectorizer_teacher_prefix.get_feature_names())\n",
    "features_std.extend(vectorizer_teacher_prefix.get_feature_names())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use count vectorizer to convert the values into one hot encoded features\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer_test_teacher_prefix_data = CountVectorizer(min_df=10,ngram_range=(1,4), max_features=100,vocabulary=list(sorted_teacher_dict.keys()), lowercase=False, binary=True)\n",
    "X_test_teacher_prefix_data = X_test['teacher_prefix']\n",
    "X_test_teacher_prefix_data.fillna(\"Mrs.\", inplace = True) \n",
    "teacher_prefix_notnull = X_test_teacher_prefix_data[pd.notnull(X_test_teacher_prefix_data)]\n",
    "vectorizer_test_teacher_prefix_data.fit(teacher_prefix_notnull.values)\n",
    "X_test_teacher_prefix_one_hot = vectorizer_test_teacher_prefix_data.transform(teacher_prefix_notnull.values)\n",
    "print(\"Shape of matrix after one hot encodig \",X_test_teacher_prefix_one_hot.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use count vectorizer to convert the values into one hot encoded features\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer_cv_teacher_prefix = CountVectorizer(min_df=10,ngram_range=(1,4), max_features=100,vocabulary=list(sorted_teacher_dict.keys()), lowercase=False, binary=True)\n",
    "X_cv_teacher_prefix_data = X_cv['teacher_prefix']\n",
    "X_cv_teacher_prefix_data.fillna(\"Mrs.\", inplace = True) \n",
    "teacher_prefix_notnull = X_cv_teacher_prefix_data[pd.notnull(X_cv_teacher_prefix_data)]\n",
    "vectorizer_cv_teacher_prefix.fit(teacher_prefix_notnull.values)\n",
    "print(vectorizer_cv_teacher_prefix.get_feature_names())\n",
    "X_cv_teacher_prefix_one_hot = vectorizer_cv_teacher_prefix.transform(teacher_prefix_notnull.values)\n",
    "print(\"Shape of matrix after one hot encodig \",X_cv_teacher_prefix_one_hot.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorization of price for X_train,X_test, X_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head(1)\n",
    "X_test.head(1)\n",
    "X_cv.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "normalizer = Normalizer()\n",
    "# normalizer.fit(X_train['price'].values)\n",
    "# this will rise an error Expected 2D array, got 1D array instead: \n",
    "# array=[105.22 215.96  96.01 ... 368.98  80.53 709.67].\n",
    "# Reshape your data either using \n",
    "# array.reshape(-1, 1) if your data has a single feature \n",
    "# array.reshape(1, -1)  if it contains a single sample.\n",
    "\n",
    "#normalizer.fit(X_train['price'].values.reshape(-1,1))\n",
    "\n",
    "X_train_price_norm = normalizer.transform(X_train['price'].values.reshape(-1,1))\n",
    "X_test_price_norm = normalizer.transform(X_test['price'].values.reshape(-1,1))\n",
    "X_cv_price_norm = normalizer.transform(X_cv['price'].values.reshape(-1,1))\n",
    "\n",
    "print(\"After vectorizations\")\n",
    "print(X_train_price_norm.shape, y_train.shape)\n",
    "print(X_test_price_norm.shape, y_test.shape)\n",
    "print(X_cv_price_norm.shape, y_cv.shape)\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of words of project_title for X_train,X_test, X_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROJECT_TITLE BOW\n",
    "# We are considering only the words which appeared in at least 10 documents(rows or projects). \n",
    "vectorizer_bow_project_title = CountVectorizer(min_df=10,ngram_range=(1,4),vocabulary=list(sorted_project_title_dict.keys()))\n",
    "X_train_project_title_bow = vectorizer_bow_project_title.fit_transform(X_train['project_title'])\n",
    "X_test_project_title_bow = vectorizer_bow_project_title.transform(X_test['project_title'])\n",
    "X_cv_project_title_bow = vectorizer_bow_project_title.transform(X_cv['project_title'])\n",
    "print(\"Shape of matrix X_train_project_title_bow after one hot encodig \",X_train_project_title_bow .shape)\n",
    "print(\"Shape of matrix X_test_project_title_bow after one hot encodig \",X_test_project_title_bow .shape)\n",
    "print(\"Shape of matrix X_cv_project_title_bow after one hot encodig \",X_cv_project_title_bow .shape)\n",
    "\n",
    "features_bow.extend(vectorizer_bow_project_title.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of words of preprocessed_essays for X_train,X_test, X_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are considering only the words which appeared in at least 10 documents(rows or projects).\n",
    "vectorizer_bow_essays = CountVectorizer(min_df=10)\n",
    "X_train_text_bow = vectorizer_bow_essays.fit_transform(X_train_preprocessed_essays)\n",
    "X_test_text_bow = vectorizer_bow_essays.transform(X_test_preprocessed_essays)\n",
    "X_cv_text_bow = vectorizer_bow_essays.transform(X_cv_preprocessed_essays)\n",
    "\n",
    "features_bow.extend(vectorizer_bow_essays.get_feature_names())\n",
    "\n",
    "#print (vectorizer_bow_essays.get_feature_names())\n",
    "print(\"Shape of matrix X_train_text_bow after one hot encodig \",X_train_text_bow.shape)\n",
    "print(\"Shape of matrix X_test_text_bow after one hot encodig \",X_test_text_bow.shape)\n",
    "print(\"Shape of matrix X_cv_text_bow after one hot encodig \",X_cv_text_bow.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF of preprocessed_essays for X_train,X_test, X_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_model = TfidfVectorizer()\n",
    "tfidf_model.fit(X_train_preprocessed_essays)\n",
    "# we are converting a dictionary with word as a key, and the idf as a value\n",
    "dictionary = dict(zip(tfidf_model.get_feature_names(), list(tfidf_model.idf_)))\n",
    "X_train_tfidf_words = set(tfidf_model.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF of preprocessed_essays for X_train,X_test, X_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer_tfidf_essays = TfidfVectorizer()\n",
    "X_train_text_tfidf = vectorizer_tfidf_essays.fit_transform(X_train_preprocessed_essays)\n",
    "X_test_text_tfidf = vectorizer_tfidf_essays.transform(X_test_preprocessed_essays)\n",
    "X_cv_text_tfidf = vectorizer_tfidf_essays.transform(X_cv_preprocessed_essays)\n",
    "print(\"Shape of matrix X_train_text_tfidf after one hot encodig \",X_train_text_tfidf.shape)\n",
    "print(\"Shape of matrix X_test_text_tfidf after one hot encodig \",X_test_text_tfidf.shape)\n",
    "print(\"Shape of matrix X_cv_text_tfidf after one hot encodig \",X_cv_text_tfidf.shape)\n",
    "\n",
    "features_tfidf.extend(vectorizer_tfidf_essays.get_feature_names())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF of Project Title for X_train,X_test, X_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer_tfidf_project_title = TfidfVectorizer(min_df=10)\n",
    "X_train_project_title_tfidf = vectorizer_tfidf_project_title.fit_transform((X_train['project_title']))\n",
    "X_test_project_title_tfidf = vectorizer_tfidf_project_title.transform((X_test['project_title']))\n",
    "X_cv_project_title_tfidf = vectorizer_tfidf_project_title.transform((X_cv['project_title']))\n",
    "print(\"Shape of matrix  X_train_project_title_tfidf after one hot encodig \",X_train_project_title_tfidf.shape)\n",
    "print(\"Shape of matrix  X_test_project_title_tfidf after one hot encodig \",X_test_project_title_tfidf.shape)\n",
    "print(\"Shape of matrix  X_cv_project_title_tfidf after one hot encodig \",X_cv_project_title_tfidf.shape)\n",
    "\n",
    "features_tfidf.extend(vectorizer_tfidf_project_title.get_feature_names())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF AVG W2V for Project Title for X_train,X_test, X_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average Word2Vec\n",
    "# compute average word2vec for each review.\n",
    "X_train_project_title_avg_w2v_vectors = []; # the avg-w2v for each sentence/review is stored in this list\n",
    "for sentence in tqdm(X_train['project_title']): # for each review/sentence\n",
    "    vector = np.zeros(300) # as word vectors are of zero length\n",
    "    cnt_words =0; # num of words with a valid vector in the sentence/review\n",
    "    for word in sentence.split(): # for each word in a review/sentence\n",
    "        if word in glove_words:\n",
    "            vector += model[word]\n",
    "            cnt_words += 1\n",
    "    if cnt_words != 0:\n",
    "        vector /= cnt_words\n",
    "    X_train_project_title_avg_w2v_vectors.append(vector)\n",
    "\n",
    "print(len(X_train_project_title_avg_w2v_vectors))\n",
    "print(len(X_train_project_title_avg_w2v_vectors[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average Word2Vec\n",
    "# compute average word2vec for each review.\n",
    "X_test_project_title_avg_w2v_vectors = []; # the avg-w2v for each sentence/review is stored in this list\n",
    "for sentence in tqdm(X_test['project_title']): # for each review/sentence\n",
    "    vector = np.zeros(300) # as word vectors are of zero length\n",
    "    cnt_words =0; # num of words with a valid vector in the sentence/review\n",
    "    for word in sentence.split(): # for each word in a review/sentence\n",
    "        if word in glove_words:\n",
    "            vector += model[word]\n",
    "            cnt_words += 1\n",
    "    if cnt_words != 0:\n",
    "        vector /= cnt_words\n",
    "    X_test_project_title_avg_w2v_vectors.append(vector)\n",
    "\n",
    "print(len(X_test_project_title_avg_w2v_vectors))\n",
    "print(len(X_test_project_title_avg_w2v_vectors[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average Word2Vec\n",
    "# compute average word2vec for each review.\n",
    "X_cv_project_title_avg_w2v_vectors = []; # the avg-w2v for each sentence/review is stored in this list\n",
    "for sentence in tqdm(X_cv['project_title']): # for each review/sentence\n",
    "    vector = np.zeros(300) # as word vectors are of zero length\n",
    "    cnt_words =0; # num of words with a valid vector in the sentence/review\n",
    "    for word in sentence.split(): # for each word in a review/sentence\n",
    "        if word in glove_words:\n",
    "            vector += model[word]\n",
    "            cnt_words += 1\n",
    "    if cnt_words != 0:\n",
    "        vector /= cnt_words\n",
    "    X_cv_project_title_avg_w2v_vectors.append(vector)\n",
    "\n",
    "print(len(X_cv_project_title_avg_w2v_vectors))\n",
    "print(len(X_cv_project_title_avg_w2v_vectors[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge two sparse matrices: https://stackoverflow.com/a/19710648/4084039\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "\n",
    "X_tr = hstack((X_train_price_norm,X_train_sub_categories_one_hot,X_train_teacher_prefix_one_hot)).tocsr()\n",
    "X_cr = hstack((X_cv_price_norm,X_cv_sub_categories_one_hot,X_cv_teacher_prefix_one_hot)).tocsr()\n",
    "X_te = hstack((X_test_price_norm,X_test_sub_categories_one_hot,X_test_teacher_prefix_one_hot)).tocsr()\n",
    "\n",
    "#print (X_train_price_norm)\n",
    "X_tr_bow = hstack((X_train_price_norm,X_train_sub_categories_one_hot,X_train_teacher_prefix_one_hot,X_train_text_bow,X_train_project_title_bow)).tocsr()\n",
    "X_cr_bow = hstack((X_cv_price_norm,X_cv_sub_categories_one_hot,X_cv_teacher_prefix_one_hot,X_cv_text_bow,X_cv_project_title_bow)).tocsr()\n",
    "X_te_bow = hstack((X_test_price_norm,X_test_sub_categories_one_hot,X_test_teacher_prefix_one_hot,X_test_text_bow,X_test_project_title_bow)).tocsr()\n",
    "\n",
    "\n",
    "#print (X_train_price_norm)\n",
    "#X_tr_bow = hstack((X_train_price_norm,,X_train_teacher_prefix_one_hot,X_train_text_bow,X_train_project_title_bow)).tocsr()\n",
    "#X_cr_bow = hstack((X_cv_price_norm,,X_cv_teacher_prefix_one_hot,X_cv_text_bow,X_cv_project_title_bow)).tocsr()\n",
    "#X_te_bow = hstack((X_test_price_norm,,X_test_teacher_prefix_one_hot,X_test_text_bow,X_test_project_title_bow)).tocsr()\n",
    "\n",
    "\n",
    "X_tr_tfidf = hstack((X_train_sub_categories_one_hot,X_train_teacher_prefix_one_hot,X_train_price_norm,X_train_project_title_tfidf,X_train_text_tfidf)).tocsr()\n",
    "X_cr_tfidf = hstack((X_cv_sub_categories_one_hot,X_cv_teacher_prefix_one_hot,X_cv_price_norm,X_cv_project_title_tfidf,X_cv_text_tfidf)).tocsr()\n",
    "X_te_tfidf = hstack((X_test_sub_categories_one_hot,X_test_teacher_prefix_one_hot,X_test_price_norm,X_test_project_title_tfidf,X_test_text_tfidf)).tocsr()\n",
    "\n",
    "X_tr_tfidf_w2v = hstack((X_train_sub_categories_one_hot,X_train_teacher_prefix_one_hot,X_train_price_norm,X_train_project_title_avg_w2v_vectors)).tocsr()\n",
    "X_cr_tfidf_w2v = hstack((X_cv_sub_categories_one_hot,X_cv_teacher_prefix_one_hot,X_cv_price_norm,X_cv_project_title_avg_w2v_vectors)).tocsr()\n",
    "X_te_tfidf_w2v = hstack((X_test_sub_categories_one_hot,X_test_teacher_prefix_one_hot,X_test_price_norm,X_test_project_title_avg_w2v_vectors)).tocsr()\n",
    "\n",
    "\n",
    "X_tr_avg_w2v = hstack((X_train_sub_categories_one_hot,X_train_teacher_prefix_one_hot,X_train_price_norm,X_train_project_title_avg_w2v_vectors)).tocsr()\n",
    "X_cr_avg_w2v = hstack((X_cv_sub_categories_one_hot,X_cv_teacher_prefix_one_hot,X_cv_price_norm,X_cv_project_title_avg_w2v_vectors)).tocsr()\n",
    "X_te_avg_w2v = hstack((X_test_sub_categories_one_hot,X_test_teacher_prefix_one_hot,X_test_price_norm,X_test_project_title_avg_w2v_vectors)).tocsr()\n",
    "\n",
    "#print(\"Final Data matrix\")\n",
    "print(X_tr.shape, y_train.shape)\n",
    "print(X_cr.shape, y_cv.shape)\n",
    "print(X_te.shape, y_test.shape)\n",
    "\n",
    "print(\"=\"*100)\n",
    "\n",
    "print(X_tr_tfidf.shape, y_train.shape)\n",
    "print(X_cr_tfidf.shape, y_cv.shape)\n",
    "print(X_te_tfidf.shape, y_test.shape)\n",
    "print(\"=\"*100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4: Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ol>\n",
    "    <li><strong>Apply Multinomial NaiveBayes on these feature sets</strong>\n",
    "        <ul>\n",
    "            <li><font color='red'>Set 1</font>: categorical, numerical features + project_title(BOW) + preprocessed_eassay (BOW)</li>\n",
    "            <li><font color='red'>Set 2</font>: categorical, numerical features + project_title(TFIDF)+  preprocessed_eassay (TFIDF)</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <br>\n",
    "    <li><strong>The hyper paramter tuning(find best Alpha)</strong>\n",
    "        <ul>\n",
    "    <li>Find the best hyper parameter which will give the maximum <a href='https://www.appliedaicourse.com/course/applied-ai-course-online/lessons/receiver-operating-characteristic-curve-roc-curve-and-auc-1/'>AUC</a> value</li>\n",
    "    <li>Consider a wide range of alpha values for hyperparameter tuning, start as low as 0.00001</li>\n",
    "    <li>Find the best hyper paramter using k-fold cross validation or simple cross validation data</li>\n",
    "    <li>Use gridsearch cv or randomsearch cv or you can also write your own for loops to do this task of hyperparameter tuning</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <br>\n",
    "    <li><strong>Feature importance</strong>\n",
    "        <ul>\n",
    "    <li>Find the top 10 features of positive class and top 10 features of negative class for both feature sets <font color='red'>Set 1</font> and <font color='red'>Set 2</font> using values of `feature_log_prob_` parameter of  <a href='https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html'>MultinomialNB</a> and print their corresponding feature names</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <br>\n",
    "    <li><strong>Representation of results</strong>\n",
    "        <ul>\n",
    "    <li>You need to plot the performance of model both on train data and cross validation data for each hyper parameter, like shown in the figure. Here on X-axis you will have alpha values, since they have a wide range, just to represent those alpha values on the graph, apply log function on those alpha values.\n",
    "    <img src='train_cv_auc.JPG' width=300px></li>\n",
    "    <li>Once after you found the best hyper parameter, you need to train your model with it, and find the AUC on test data and plot the ROC curve on both train and test.\n",
    "    <img src='train_test_auc.JPG' width=300px></li>\n",
    "    <li>Along with plotting ROC curve, you need to print the <a href='https://www.appliedaicourse.com/course/applied-ai-course-online/lessons/confusion-matrix-tpr-fpr-fnr-tnr-1/'>confusion matrix</a> with predicted and original labels of test data points. Please visualize your confusion matrices using <a href='https://seaborn.pydata.org/generated/seaborn.heatmap.html'>seaborn heatmaps.\n",
    "    <img src='confusion_matrix.png' width=300px></li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <br>\n",
    "    <li><strong>Conclusion</strong>\n",
    "        <ul>\n",
    "    <li>You need to summarize the results at the end of the notebook, summarize it in the table format. To print out a table please refer to this prettytable library<a href='http://zetcode.com/python/prettytable/'>  link</a> \n",
    "        <img src='summary.JPG' width=400px>\n",
    "    </li>\n",
    "        </ul>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><font color='red'>Note: Data Leakage</font></h4>\n",
    "\n",
    "1. There will be an issue of data-leakage if you vectorize the entire data and then split it into train/cv/test.\n",
    "2. To avoid the issue of data-leakag, make sure to split your data first and then vectorize it. \n",
    "3. While vectorizing your data, apply the method fit_transform() on you train data, and apply the method transform() on cv/test data.\n",
    "4. For more details please go through this <a href='https://soundcloud.com/applied-ai-course/leakage-bow-and-tfidf'>link.</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>2. Naive Bayes Validation </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>2.4 Appling NB() on different kind of featurization as mentioned in the instructions</h2>\n",
    "\n",
    "<br>Apply Naive Bayes on different kind of featurization as mentioned in the instructions\n",
    "<br> For Every model that you work on make sure you do the step 2 and step 3 of instrucations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_predict(clf, data):\n",
    "    # roc_auc_score(y_true, y_score) the 2nd parameter should be probability estimates of the positive class\n",
    "    # not the predicted outputs\n",
    "    y_data_pred = []\n",
    "    tr_loop = data.shape[0] - data.shape[0]%1000\n",
    "    # consider you X_tr shape is 49041, then your tr_loop will be 49041 - 49041%1000 = 49000\n",
    "    # in this for loop we will iterate unti the last 1000 multiplier\n",
    "    for i in range(0, tr_loop, 1000):\n",
    "        y_data_pred.extend(clf.predict_proba(data[i:i+1000])[:,1])\n",
    "    # we will be predicting for the last data points\n",
    "    if data.shape[0]%1000 !=0:\n",
    "        y_data_pred.extend(clf.predict_proba(data[tr_loop:])[:,1])\n",
    "    \n",
    "    return y_data_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are writing our own function for predict, with defined thresould\n",
    "# we will pick a threshold that will give the least fpr\n",
    "def find_best_threshold(threshould, fpr, tpr):\n",
    "    t = threshould[np.argmax(tpr*(1-fpr))]\n",
    "    # (tpr*(1-fpr)) will be maximum if your fpr is very low and tpr is very high\n",
    "    print(\"the maximum value of tpr*(1-fpr)\", max(tpr*(1-fpr)), \"for threshold\", np.round(t,3))\n",
    "    return t\n",
    "\n",
    "def predict_with_best_t(proba, threshould):\n",
    "    predictions = []\n",
    "    for i in proba:\n",
    "        if i>=threshould:\n",
    "            predictions.append(1)\n",
    "        else:\n",
    "            predictions.append(0)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multinomialNB_validation_alpha_analysis(X_tr,y_train,X_cr,y_cv):\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn.naive_bayes import MultinomialNB\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    import math\n",
    "    \"\"\"\n",
    "    y_true : array, shape = [n_samples] or [n_samples, n_classes]\n",
    "    True binary labels or binary label indicators.\n",
    "\n",
    "    y_score : array, shape = [n_samples] or [n_samples, n_classes]\n",
    "    Target scores, can either be probability estimates of the positive class, confidence values, or non-thresholded measure of\n",
    "    decisions (as returned by “decision_function” on some classifiers). \n",
    "    For binary y_true, y_score is supposed to be the score of the class with greater label.\n",
    "\n",
    "    \"\"\"\n",
    "    alphas = np.logspace(-1, 100, num=100)\n",
    "    #alphas = [0.00001, 0.0006, 0.0009,0.0001, 0.0003, 0.0004, 0.0008, 0.001,0.01, 0.07,0.09, 0.1,0.2,0.3,0.4,0.5,0.9,1]\n",
    "    #alphas = [alpha for alpha in np.arange (0,1,0.01)]\n",
    "    train_auc = []\n",
    "    cv_auc = []\n",
    "    new_alphas = []\n",
    "    for i in tqdm(alphas):\n",
    "        if (i >0  and math.log(i) >0):\n",
    "            i = math.log(i)\n",
    "            new_alphas.append(i)\n",
    "            nb = MultinomialNB(alpha=i,class_prior=[0.5,0.5])\n",
    "            nb.fit(X_tr, y_train)\n",
    "            y_train_pred = batch_predict(nb,X_tr)    \n",
    "            y_cv_pred = batch_predict(nb,X_cr)\n",
    "\n",
    "            # roc_auc_score(y_true, y_score) the 2nd parameter should be probability estimates of the positive class\n",
    "            # not the predicted outputs        \n",
    "            train_auc.append(roc_auc_score(y_train,y_train_pred))\n",
    "            cv_auc.append(roc_auc_score(y_cv, y_cv_pred))\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    plt.plot(new_alphas, train_auc, label='Train AUC')\n",
    "    plt.plot(new_alphas, cv_auc, label='CV AUC')\n",
    "\n",
    "    plt.scatter(new_alphas, train_auc, label='Train AUC points')\n",
    "    plt.scatter(new_alphas, cv_auc, label='CV AUC points')\n",
    "\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Log(alphas): hyperparameter\")\n",
    "    plt.ylabel(\"AUC\")\n",
    "    plt.title(\"ERROR PLOTS\")\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multinomialNB_validation(X_tr,y_train,X_te,y_test):\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn.naive_bayes import MultinomialNB\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "   \n",
    "    #alphas = np.logspace(-1, 100, num=10)\n",
    "    alphas = [0,0.00001, 0.0006, 0.0009,0.0001, 0.0003, 0.0004, 0.0008, 0.001,0.01, 0.07,0.09, 0.1,0.2,0.3,0.4,0.5,0.9,1]\n",
    "    nb = MultinomialNB()\n",
    "    train_auc = []\n",
    "    test_auc = []\n",
    "    grid = GridSearchCV(estimator=nb,param_grid=dict(alpha= alphas),return_train_score=True)\n",
    "\n",
    "    %time grid.fit(X_tr, y_train)\n",
    "    \n",
    "    print(\"Best grid score: %s\" % grid.best_score_)\n",
    "    print(\"Best grid estimator: %s\" % grid.best_estimator_.alpha)\n",
    "    \n",
    "    alpha =  grid.best_estimator_.alpha\n",
    "    \n",
    "    NB =   grid.best_estimator_\n",
    "    \n",
    "    print(\"Best alpha is after applying GridSearchCV: %s\" % alpha)\n",
    "\n",
    "    # 4. make class predictions for X_test_dtm\n",
    "    y_test_pred = grid.predict(X_te)    # 4. make class predictions for X_test_dtm\n",
    "    y_train_pred = grid.predict(X_tr)\n",
    "\n",
    "    # roc_auc_score(y_true, y_score) the 2nd parameter should be probability estimates of the positive class\n",
    "    # not the predicted outputs        \n",
    "    train_auc.append(roc_auc_score(y_train,y_train_pred))\n",
    "    test_auc.append(roc_auc_score(y_test, y_test_pred))\n",
    "\n",
    "    # block starts\n",
    "    train_scores_mean = grid.cv_results_['mean_train_score']\n",
    "    train_scores_std =  grid.cv_results_['std_train_score']\n",
    "    test_scores_mean =  grid.cv_results_['mean_test_score']\n",
    "    test_scores_std =   grid.cv_results_['std_test_score']\n",
    "\n",
    "    plt.figure()\n",
    "    plt.title('Model')\n",
    "    plt.xlabel('$\\\\alpha$ (alpha)')\n",
    "    plt.ylabel('Score')\n",
    "    # plot train scores\n",
    "    plt.semilogx(alphas, train_scores_mean, label='Mean Train score',\n",
    "                 color='navy')\n",
    "    # create a shaded area between [mean - std, mean + std]\n",
    "    plt.gca().fill_between(alphas,\n",
    "                           train_scores_mean - train_scores_std,\n",
    "                           train_scores_mean + train_scores_std,\n",
    "                           alpha=0.2,\n",
    "                           color='navy')\n",
    "    plt.semilogx(alphas, test_scores_mean,\n",
    "                 label='Mean Test score', color='darkorange')\n",
    "\n",
    "    # create a shaded area between [mean - std, mean + std]\n",
    "    plt.gca().fill_between(alphas,\n",
    "                           test_scores_mean - test_scores_std,\n",
    "                           test_scores_mean + test_scores_std,\n",
    "                           alpha=0.2,\n",
    "                           color='darkorange')\n",
    "\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "    \n",
    "    # block ends\n",
    "    \n",
    "    # calculate accuracy of class predictions\n",
    "    from sklearn import metrics\n",
    "    print (metrics.accuracy_score(y_test, y_test_pred))\n",
    "\n",
    "    import seaborn as sns\n",
    "    conf_mat = confusion_matrix(y_test, y_test_pred)\n",
    "    conf_mat_normalized = conf_mat.astype('float') / conf_mat.sum(axis=1)[:, np.newaxis]\n",
    "    sns.heatmap(conf_mat_normalized)\n",
    "    plt.ylabel('Test True label')\n",
    "    plt.xlabel('Test Predicted label')\n",
    "\n",
    "\n",
    "    #The ROC curve is plotted with TPR against the FPR where TPR is on y-axis and FPR is on the x-axis.\n",
    "    train_fpr, train_tpr, tr_thresholds = roc_curve(y_train, y_train_pred)\n",
    "    test_fpr, test_tpr, te_thresholds = roc_curve(y_test, y_test_pred)\n",
    "\n",
    "    plt.plot(train_fpr, train_tpr, label=\"train AUC =\"+str(auc(train_fpr, train_tpr)))\n",
    "    plt.plot(test_fpr, test_tpr, label=\"Test AUC =\"+str(auc(test_fpr, test_tpr)))\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"FPR\")\n",
    "    plt.ylabel(\"TPR\")\n",
    "    plt.title(\"AUC PLOT\")\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "    import seaborn as sns\n",
    "    conf_mat = confusion_matrix(y_test, y_test_pred)\n",
    "    conf_mat_normalized = conf_mat.astype('float') / conf_mat.sum(axis=1)[:, np.newaxis]\n",
    "    sns.heatmap(conf_mat_normalized)\n",
    "    plt.ylabel('Test True label')\n",
    "    plt.xlabel('Test Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to speculate the performance of the model using ROC Curve?\n",
    "#### An excellent model has AUC near to the 1 which means it has good measure of separability. A poor model has AUC near to the 0 which means it has worst measure of separability. In fact it means it is reciprocating the result. It is predicting 0s as 1s and 1s as 0s. And when AUC is 0.5, it means model has no class separation capacity whatsoever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NB_best_validation(X_tr,y_train,X_te, y_test,best_alpha,count_vect):\n",
    "    # https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html#sklearn.metrics.roc_curve\n",
    "    from sklearn.metrics import roc_curve, auc\n",
    "    from sklearn.naive_bayes import MultinomialNB\n",
    "    \n",
    "    # use model MultinomialNB, pass best aplha found already in earlier analysis.\n",
    "    nb = MultinomialNB(alpha=best_alpha,class_prior=[0.5,0.5])\n",
    "    nb.fit(X_tr, y_train)\n",
    "    # roc_auc_score(y_true, y_score) the 2nd parameter should be probability estimates of the positive class\n",
    "    # not the predicted outputs\n",
    "\n",
    "    y_train_pred = nb.predict(X_tr)\n",
    "    y_test_pred = nb.predict(X_te)\n",
    "\n",
    "    #The ROC curve is plotted with TPR against the FPR where TPR is on y-axis and FPR is on the x-axis.\n",
    "    train_fpr, train_tpr, tr_thresholds = roc_curve(y_train, y_train_pred)\n",
    "    test_fpr, test_tpr, te_thresholds = roc_curve(y_test, y_test_pred)\n",
    "\n",
    "    # plot AUC curve. AUC curve should show best accuracy rate, since best aplha is used in the logic.\n",
    "    plt.plot(train_fpr, train_tpr, label=\"train AUC =\"+str(auc(train_fpr, train_tpr)))\n",
    "    plt.plot(test_fpr, test_tpr, label=\"Test AUC =\"+str(auc(test_fpr, test_tpr)))\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"FPR\")\n",
    "    plt.ylabel(\"TPR\")\n",
    "    plt.title(\"AUC PLOT\")\n",
    "    plt.grid()\n",
    "    plt.show\n",
    "    \n",
    "    print(\"=\"*100)\n",
    "    import seaborn as sns\n",
    "   \n",
    "    conf_mat = confusion_matrix(y_test, y_test_pred)\n",
    "    conf_mat_normalized = conf_mat.astype('float') / conf_mat.sum(axis=1)[:, np.newaxis]\n",
    "    sns.heatmap(conf_mat_normalized)\n",
    "    plt.ylabel('Test True label')\n",
    "    plt.xlabel('Test Predicted label')\n",
    "    \n",
    "    neg_class_prob_sorted = nb.feature_log_prob_[0, :].argsort()\n",
    "    pos_class_prob_sorted = nb.feature_log_prob_[1, :].argsort()\n",
    "\n",
    "   \n",
    "    print(\"Top 10 positive features %s\" % np.take(count_vect, pos_class_prob_sorted[:10]))\n",
    "    print(\"=\"*100)\n",
    "    print(\"Top 10 negative features %s\" % np.take(count_vect, neg_class_prob_sorted[:10]))\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NBAnalysis_cross_validation(X_tr,y_tr,X_cr,y_cv):\n",
    "    from sklearn import model_selection\n",
    "    from mlxtend.plotting import plot_decision_regions\n",
    "    from sklearn.naive_bayes import MultinomialNB\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    # Import classification report and confusion matrix to evaluate predictions\n",
    "    from sklearn.metrics import classification_report, confusion_matrix\n",
    "    \n",
    "    # split the data set into train and test\n",
    "    # Break up the data as you see test data to 30%, train data is 70%. so we break data into two matrix. \n",
    "    # x1 and y1 would be 70% as train data and x-test and y_test will be test data as 30%.\n",
    " \n",
    "    error_rate = []\n",
    "    \n",
    "   # X_1, X_test, y_1, y_test = model_selection.train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "    # split the train data set into cross validation train and cross validation test\n",
    "    #X_tr, X_cv, y_tr, y_cv = model_selection.train_test_split(X_1, y_1, test_size=0.3)\n",
    "\n",
    "    #Evaluate alternative K-values for better predictionsTo simplify the process of evaluating multiple cases of k-values, \n",
    "    #we create a function to derive the error using the average where our predictions were not equal to the test values.\n",
    "    for i in  [0.0000001,0.00001,0.0001, 0.001, 0.01, 0.06,0.07,0.1, 0.2,0.3,0.4,0.5,0.9,1,2]: \n",
    "        nb = MultinomialNB(alpha=i,class_prior=[0.5,0.5]) # Number of nearest neighbor is i.\n",
    "\n",
    "        # fitting the model on crossvalidation train\n",
    "        nb.fit(X_tr, y_tr)\n",
    "\n",
    "        # predict the response on the crossvalidation train\n",
    "        y_pred = nb.predict(X_cr)  # predicting the value using cross validation data. \n",
    "\n",
    "        # evaluate CV accuracy\n",
    "        acc = accuracy_score(y_cv, y_pred, normalize=True) * float(100)  # I get the accuracy score. \n",
    "        print('\\nCV accuracy for Alpha = %.6f is %d' % (i, acc))\n",
    "    \n",
    "        # evaluate CV accuracy\n",
    "        error_rate.append(np.mean(y_pred != y_cv))\n",
    "        #print (error_rate)\n",
    "   \n",
    "    # Configure and plot error rate over k values\n",
    "    plt.figure(figsize=(10,4))\n",
    "    plt.plot([0.0000001,0.00001,0.0001, 0.001, 0.01, 0.06,0.07,0.1, 0.2,0.3,0.4,0.5,0.9,1,2], error_rate, color='blue', linestyle='dashed', marker='o', markerfacecolor='red', markersize=10)\n",
    "    plt.title('Error Rate vs. Alphas')\n",
    "    plt.xlabel('Alphas')\n",
    "    plt.ylabel('Error Rate')\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>2.4 Appling MultiNomialNB on different kind of featurization as mentioned in the instructions</h2>\n",
    "\n",
    "<br>Apply KMultiNomialNBNN on different kind of featurization as mentioned in the instructions\n",
    "<br> For Every model that you work on make sure you do the step 2 and step 3 of instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>2.3 Make Data Model Ready: encoding eassay, and project_title</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.0  Alpha Validation  for MultinomialNB on   Set 1: categorical, numerical features + project_title(BOW) + preprocessed_essay (BOW),<font color='red'> SET 1</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Alpha Validation  for MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multinomialNB_validation_alpha_analysis(X_tr,y_train,X_te,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.1  Alpha Validation  for MultinomialNB on  BOW - Set 1: categorical, numerical features + project_title(BOW) + preprocessed_essay (BOW),<font color='red'> SET 1</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please write all the code with proper documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kbest for BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multinomialNB_validation_alpha_analysis (X_tr_bow,y_train,X_cr_bow,y_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "multinomialNB_validation_alpha_analysis(X_tr_bow,y_train,X_cr_bow,y_cv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.2 Alpha Validation  for MultinomialNB on TFIDF Set 2: categorical, numerical features + project_title(TFIDF)+ preprocessed_essay (TFIDF),<font color='red'> SET 2</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multinomialNB_validation_alpha_analysis(X_tr_tfidf,y_train,X_cr_tfidf,y_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5.1 <font color='red'> Alpha-Analysis  <font color='blue'> categorical, numerical features + project_title(BOW) + preprocessed_essay (BOW),<font color='red'> SET 1</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NBAnalysis_cross_validation(X_tr_bow,y_train,X_cr_bow,y_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5.2 <font color='red'> Alpha-Analysis   <font color='blue'>  on TFIDF Set 2: categorical, numerical features + project_title(TFIDF)+ preprocessed_essay (TFIDF),<font color='red'> SET 2</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NBAnalysis_cross_validation(X_tr_tfidf,y_train,X_cr_tfidf,y_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 <font color='red'> ALPHA-BEST  <font color='blue'> categorical, numerical features + project_title(BOW) + preprocessed_essay (BOW),<font color='red'> SET 1</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best alpha is found from above analysis of BoW. using best Alpha, test accuracy is calcuated as around.\n",
    "Best_alpha=0.1\n",
    "NB_best_validation(X_tr_bow,y_train,X_cr_bow, y_cv,Best_alpha,features_bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 <font color='red'> Alpha-Best   <font color='blue'>  on TFIDF Set 2: categorical, numerical features + project_title(TFIDF)+ preprocessed_essay (TFIDF),<font color='red'> SET 2</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best alpha is found from above analysis of TfDIF. using best Alpha, test accuracy is calcuated as around.\n",
    "Best_alpha=0.7\n",
    "NB_best_validation(X_tr_tfidf,y_train,X_cr_tfidf,y_cv,Best_alpha,features_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 <font color='red'> Alpha-Best   <font color='blue'>  on - categorical, numerical features + project_title + preprocessed_essay ,<font color='red'> SET 4</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best alpha is found from above analysis of Std. using best Alpha, test accuracy is calcuated as around.\n",
    "Best_alpha= 0.09\n",
    "NB_best_validation(X_tr,y_train,X_cr,y_cv,Best_alpha,features_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>3. Conclusions</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of above program as below:\n",
    "### Step 1: Import the necessary Libraries\n",
    "we will need to import libraries that allow for data analysis and data visualization to get acclimated to the dataset. We will be using pandas, numpy, matplotlib and seaborn to conduct this. Data Exploration libraries\n",
    "\n",
    "### Step 2: Read in the dataset.\n",
    "We will use the pandas .read_csv() method to read in the dataset. Then we will use the. head() method to observe the first few rows of the data, to understand the information better. In our case, the feature(column) headers tell us pretty little. This is fine because we are merely trying to gain insight via classifying new data points by referencing it’s neighboring elements.\n",
    "\n",
    "### Step 3: Standardize (normalize) the data scale to prep for Multinomial NB algorithm.\n",
    "Because the distance between pairs of points plays a critical part on the classification, it is necessary to normalize the data This will generate an array of values. Again,  Naive Bayes depends on the distance between each feature. Please see Section 1 for all normalization.\n",
    "\n",
    "### Step 4: Split the normalized data into training and test sets.\n",
    "This step is required to prepare us for the fitting (i.e. training) the model later. The “X” variable is a collection of all the features. The “y” variable is the target label which specifies the classification of 1 or 0 based. Our goal will be to identify which category the new data point should fall into.\n",
    "\n",
    "Please see functions as covered below, used in above program: def multinomialNB_validation_alpha_analysis: def NB_best_validation\n",
    "\n",
    "### Step 5: Create and Train the Model.\n",
    "Here we create a Naive Bayes Object and use the .fit() method to train the model. Upon completion of the model we should receive confirmation that the training has been complete\n",
    "\n",
    "Please see functions as covered below, used in above program: def multinomialNB_validation_alpha_analysis def NB_best_validation\n",
    "\n",
    "### Step 6: Make Predictions.\n",
    "Here we review where our model was accurate and where it misclassified elements.\n",
    "\n",
    "Please see functions as covered below, used in above program: def multinomialNB_validation_alpha_analysis def NB_best_validation\n",
    "\n",
    "### Step 7: Evaluate the predictions.\n",
    "Evaluate the Model by reviewing the classification report or confusion matrix. By reviewing these tables, we are able to evaluate how accurate our model is with new values.\n",
    "\n",
    "def multinomialNB_validation_alpha_analysis def NB_best_validation:\n",
    "\n",
    "### Setp 8:Classification Report :\n",
    "This tells us our model was around 84% accurate… Print out classification report and confusion matrix\n",
    "\n",
    "print(classification_report(y_test, pred))\n",
    "\n",
    "I have covered various set to show confusion matrix.\n",
    "\n",
    "Please see section 2. covered various data sets and created confusion matrix.\n",
    "\n",
    "### Step 9: Evaluate alternative Alpha for better predictions.\n",
    "To simplify the process of evaluating multiple cases of Alpha values, we create a function to derive the error using the average where our predictions were not equal to the test values.\n",
    "\n",
    "Please see section 2. covered various data sets and created error accuracy reports.\n",
    "\n",
    "### Step 10: Plot Error Rate\n",
    "Here we see that the error rate continues to decrease as we increase the Alpha. A picture tells a thousand words. Or at least here, we are able to understand what value of Alpha leads to an optimal model. The Alpha of 1 or 0.9 seems to give a decent error rate without too much noise.\n",
    "\n",
    "### Step 11: Adjust Alpha value per error rate evaluations \n",
    "This is just fine tuning our model to increase accuracy. We will need to retrain our model with the new Alpha.\n",
    "Please see section 3 in above program. we have created confusion matrix for optimal Alpha value for various data sets. As we can see for optimal Alpha, Accuracy is much higher - so prediction is much better.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
